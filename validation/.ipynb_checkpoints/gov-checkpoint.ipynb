{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 764,
   "id": "48d4dcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('all_listings.json',\"r\") as f:\n",
    "    all_listings = json.load(f)\n",
    "import json\n",
    "with open('listings.json',\"r\") as f:\n",
    "    listings = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cd2cb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "id": "49b2e7b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['력사학',\n",
       " '경제학',\n",
       " '지구환경과학 및 지질학',\n",
       " '수학',\n",
       " '생명과학',\n",
       " '화학',\n",
       " '물리학',\n",
       " '정보과학',\n",
       " '력사,법률',\n",
       " '철학,경제학',\n",
       " '어문학',\n",
       " '법률학',\n",
       " '철학',\n",
       " '자연과학']"
      ]
     },
     "execution_count": 765,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_names = [l[0].split(\": \")[1].strip() for l in listings]\n",
    "subject_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "id": "4e1cedac",
   "metadata": {},
   "outputs": [],
   "source": [
    "gov_website = dict(zip(subject_names, all_listings))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "id": "4c1efe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"https://unibook.unikorea.go.kr/material/\"\n",
    "\n",
    "import re\n",
    "for k,v in gov_website.items():\n",
    "    for i,volume in enumerate(v):\n",
    "        date = re.findall(r'\\d+', volume[0][0])\n",
    "        date = [d for d in date if len(d) <= 2]\n",
    "        date_of_seizure, status, collection_count = volume[0][2:5]\n",
    "        link = base+volume[0][-1]\n",
    "        volume[0] = [int(date[0]),int(date[1]),date_of_seizure, status,collection_count,link]\n",
    "        t = [vol,no,date_of_seizure,status,collection_count,link]\n",
    "        \n",
    "        for ii,articles in enumerate(volume[1]):\n",
    "            del articles[2]\n",
    "            del articles[0]\n",
    "            articles[0] = articles[0].strip()\n",
    "            authors = articles[1].replace(\";\",\",\")\n",
    "            authors = authors.split(\",\")\n",
    "            authors = [a.strip() for a in authors]\n",
    "            authors = \",\".join(authors)\n",
    "            articles[1] = authors\n",
    "            if \"편집부\" in articles:\n",
    "                del v[i][1][ii]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "id": "5cf56fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in gov_website.items():\n",
    "    for volume in v:\n",
    "        new_v = set(tuple(x) for x in volume[1])\n",
    "        new_v = [list(x) for x in new_v]\n",
    "        volume[1] = new_v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4389d183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('master_dict.json',\"r\") as f:\n",
    "    master_dict = json.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "52e42eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Name': '철학,경제학', 'Index': 6, 'Year': 2016, 'No': 2, 'Language': 'ko', 'Volume': 6}\n"
     ]
    }
   ],
   "source": [
    "for k,v in master_dict.items():\n",
    "    journal = v[\"Journal Info\"]\n",
    "    if journal[\"Name\"] == \"철학,경제학\":\n",
    "        if journal[\"Year\"] == 2016:\n",
    "            print (journal)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0d46b185",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in master_dict.items():\n",
    "    journal = v[\"Journal Info\"]\n",
    "    if journal[\"Name\"] == \"력사,법률\":\n",
    "        year = journal[\"Year\"]\n",
    "        new_volume = history_law_volume(year)\n",
    "        journal[\"Volume\"] = new_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bcdcf75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in master_dict.items():\n",
    "    journal = v[\"Journal Info\"]\n",
    "    if journal[\"Name\"] == \"어문학\":\n",
    "        year = journal[\"Year\"]\n",
    "        old_volume = journal[\"Volume\"]\n",
    "        new_volume = linguistics_volume(year)\n",
    "        journal[\"Volume\"] = new_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1b638610",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linguistics_volume(year,volume):\n",
    "    known_year = 2016\n",
    "    known_vol = 62\n",
    "    deduced_volume = -(known_year - year - known_vol)\n",
    "    return deduced_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "48ffb5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def history_law_volume(year):\n",
    "    known_year = 2018\n",
    "    known_vol = 64\n",
    "    deduced_volume = -(known_year - year - known_vol)\n",
    "    return deduced_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba52660c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_volume(year):\n",
    "    known_year = 2018\n",
    "    known_vol = 64\n",
    "    deduced_volume = -(known_year - year - known_vol)\n",
    "    return deduced_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c5085290",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ko_deduce_volume(year):\n",
    "    return year+1954\n",
    "def en_deduce_volume(year):\n",
    "    return year-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "377e0681",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in master_dict.items():\n",
    "    journal = v[\"Journal Info\"]\n",
    "    if journal[\"Language\"] == \"ko\":\n",
    "        deduced_volume = ko_deduce_volume(journal[\"Year\"])\n",
    "        journal[\"Volume\"] = deduced_volume\n",
    "    elif journal[\"Language\"] == \"en\":\n",
    "        if journal[\"Year\"] == 2019:\n",
    "            deduced_volume = 5\n",
    "            journal[\"Volume\"] = deduced_volume\n",
    "            continue\n",
    "        elif journal[\"Index\"] == 2:\n",
    "            if journal[\"Year\"] == 2014:\n",
    "                deduced_volume = 2\n",
    "                journal[\"Volume\"] = deduced_volume\n",
    "                continue\n",
    "        elif journal[\"Index\"] == 1:\n",
    "            if journal[\"Year\"] == 2014:\n",
    "                deduced_volume = 3\n",
    "                journal[\"Volume\"] = deduced_volume\n",
    "                continue\n",
    "            if journal[\"Year\"] == 2015:\n",
    "                deduced_volume = 4\n",
    "                journal[\"Volume\"] = deduced_volume\n",
    "                continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "83613211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deduce_volume(6,2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0f772c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('fixed_volume_master_dict.json', 'w') as f:\n",
    "    json.dump(master_dict, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709ff757",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b5c3a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1051,
   "id": "5e0aaa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "from operator import itemgetter\n",
    "\n",
    "comparison = []\n",
    "\n",
    "for subject,gov_data in gov_website.items():\n",
    "    for volume in gov_data:\n",
    "        ## finding journal match\n",
    "        vol,no = volume[0][:2]\n",
    "        hashes = []\n",
    "        \n",
    "        ## iterating master_dict for hashes\n",
    "        for md5hash,metadata in master_dict.items():\n",
    "            j = metadata[\"Journal Info\"]\n",
    "            if j[\"Name\"] == subject:\n",
    "                if j[\"Volume\"] == vol:\n",
    "                    if j[\"No\"] == no:\n",
    "                        hashes.append(md5hash)\n",
    "        \n",
    "        ## keying those hashes to compare information:\n",
    "        my_collection = []\n",
    "        for h in hashes:\n",
    "            title = master_dict[h][\"Title\"].strip()\n",
    "            author = \",\".join(master_dict[h][\"Author\"])\n",
    "            start = master_dict[h][\"Start Page\"]\n",
    "            end = master_dict[h][\"End Page\"]\n",
    "            if not start:\n",
    "                start = 0\n",
    "                end = 0\n",
    "            page_range = f\"{start:03}\"+\"-\"+ f\"{end:03}\"\n",
    "            my_collection.append([title,author,page_range])\n",
    "        \n",
    "        \n",
    "        my_collection = sorted(my_collection, key=itemgetter(2))\n",
    "        gov_collection = sorted(volume[1], key=itemgetter(2))\n",
    "        \n",
    "        comparison.append([subject,vol,no,my_collection,gov_collection])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56507838",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 980,
   "id": "42a5302b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import zip_longest  \n",
    "\n",
    "row_count = 0\n",
    "with xlsxwriter.Workbook('test4.xlsx') as workbook:\n",
    "    worksheet = workbook.add_worksheet()\n",
    "    \n",
    "    data_format1 = workbook.add_format({'bg_color': '#a3c9ff'})\n",
    "    data_format2 = workbook.add_format({'bg_color': '#d1e4ff'})\n",
    "\n",
    "    for journal_no, journal in enumerate(comparison):\n",
    "        info = journal[0]+\" Vol.\"+str(journal[1])+\" No.\"+str(journal[2])\n",
    "        \n",
    "        my,gov = journal[-2:]\n",
    "        my = sorted(my, key=itemgetter(1))\n",
    "        gov = sorted(gov, key=itemgetter(1))\n",
    "        zipped = list(zip_longest(my, gov,fillvalue=[\"\",\"\",\"\"]))\n",
    "    \n",
    "        titles =[[item[0] for item in order] for order in zipped]\n",
    "        authors = [[item[1] for item in order] for order in zipped]\n",
    "        pages = [[item[2] for item in order] for order in zipped]\n",
    "        \n",
    "        idx = [i for i,title in enumerate(titles) if not title[1].isdigit()]\n",
    "        \n",
    "        titles = [title for i,title in enumerate(titles) if i in idx]\n",
    "        authors = [author for i,author in enumerate(authors) if i in idx]\n",
    "        pages = [page for i,page in enumerate(pages) if i in idx]\n",
    "        \n",
    "        \n",
    "        worksheet.set_row(row_count, cell_format=data_format1)\n",
    "        worksheet.write(row_count, 0, info)\n",
    "        row_count+=1\n",
    "        \n",
    "        worksheet.set_row(row_count, cell_format=data_format2)\n",
    "        worksheet.write(row_count, 0, \"my title\")\n",
    "        worksheet.write(row_count, 1, \"gov title\")\n",
    "        for i,title in enumerate(titles):\n",
    "            worksheet.write_row(row_count+i+1, 0, title)\n",
    "            worksheet.set_column(0, 1, 50)\n",
    "            \n",
    "        worksheet.write(row_count, 2, \"my author\")\n",
    "        worksheet.write(row_count, 3, \"gov author\")\n",
    "        for i,author in enumerate(authors):\n",
    "            worksheet.write_row(row_count+i+1, 2, author)\n",
    "            worksheet.set_column(2, 3, 10)\n",
    "\n",
    "        worksheet.write(row_count, 4, \"my pages\")\n",
    "        worksheet.write(row_count, 5, \"gov pages\")\n",
    "        for i,page in enumerate(pages):\n",
    "            worksheet.write_row(row_count+i+1, 4, page)\n",
    "            worksheet.set_column(4, 5, 10)\n",
    "            \n",
    "        row_count+=len(titles)\n",
    "        row_count+=2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87b5232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1079,
   "id": "a568c42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My collection is missing 력사,법률 Vol.62 No.2. Total articles are 27\n",
      "My collection is missing 력사,법률 Vol.62 No.1. Total articles are 27\n",
      "My collection is missing 력사,법률 Vol.61 No.4. Total articles are 31\n",
      "My collection is missing 력사,법률 Vol.61 No.3. Total articles are 33\n",
      "My collection is missing 력사,법률 Vol.61 No.2. Total articles are 22\n",
      "My collection is missing 력사,법률 Vol.61 No.1. Total articles are 31\n",
      "My collection is missing 력사,법률 Vol.60 No.4. Total articles are 32\n",
      "My collection is missing 력사,법률 Vol.60 No.3. Total articles are 31\n",
      "My collection is missing 력사,법률 Vol.60 No.2. Total articles are 29\n",
      "My collection is missing 력사,법률 Vol.60 No.1. Total articles are 33\n",
      "My collection is missing 력사,법률 Vol.59 No.4. Total articles are 37\n",
      "My collection is missing 력사,법률 Vol.59 No.3. Total articles are 33\n",
      "My collection is missing 력사,법률 Vol.59 No.2. Total articles are 34\n",
      "My collection is missing 력사,법률 Vol.59 No.1. Total articles are 32\n",
      "My collection is missing 력사,법률 Vol.58 No.4. Total articles are 30\n",
      "My collection is missing 력사,법률 Vol.58 No.3. Total articles are 32\n",
      "My collection is missing 력사,법률 Vol.58 No.2. Total articles are 28\n",
      "My collection is missing 력사,법률 Vol.58 No.1. Total articles are 30\n",
      "My collection is missing 력사,법률 Vol.57 No.4. Total articles are 30\n",
      "My collection is missing 력사,법률 Vol.57 No.3. Total articles are 31\n",
      "My collection is missing 철학,경제학 Vol.62 No.2. Total articles are 37\n",
      "My collection is missing 철학,경제학 Vol.62 No.1. Total articles are 45\n",
      "My collection is missing 철학,경제학 Vol.61 No.4. Total articles are 45\n",
      "My collection is missing 철학,경제학 Vol.61 No.3. Total articles are 48\n",
      "My collection is missing 철학,경제학 Vol.61 No.2. Total articles are 34\n",
      "My collection is missing 철학,경제학 Vol.61 No.1. Total articles are 39\n",
      "My collection is missing 철학,경제학 Vol.60 No.4. Total articles are 39\n",
      "My collection is missing 철학,경제학 Vol.60 No.3. Total articles are 32\n",
      "My collection is missing 철학,경제학 Vol.60 No.2. Total articles are 31\n",
      "My collection is missing 철학,경제학 Vol.60 No.1. Total articles are 30\n",
      "My collection is missing 철학,경제학 Vol.59 No.4. Total articles are 34\n",
      "My collection is missing 철학,경제학 Vol.59 No.3. Total articles are 35\n",
      "My collection is missing 철학,경제학 Vol.59 No.2. Total articles are 38\n",
      "My collection is missing 철학,경제학 Vol.58 No.4. Total articles are 38\n",
      "My collection is missing 철학,경제학 Vol.58 No.3. Total articles are 35\n",
      "My collection is missing 철학,경제학 Vol.58 No.2. Total articles are 36\n",
      "My collection is missing 철학,경제학 Vol.58 No.1. Total articles are 34\n",
      "My collection is missing 어문학 Vol.62 No.2. Total articles are 29\n",
      "My collection is missing 어문학 Vol.62 No.1. Total articles are 27\n",
      "My collection is missing 어문학 Vol.61 No.4. Total articles are 29\n",
      "My collection is missing 어문학 Vol.61 No.2. Total articles are 22\n",
      "My collection is missing 어문학 Vol.61 No.1. Total articles are 30\n",
      "My collection is missing 어문학 Vol.60 No.4. Total articles are 42\n",
      "My collection is missing 어문학 Vol.60 No.3. Total articles are 31\n",
      "My collection is missing 어문학 Vol.60 No.2. Total articles are 30\n",
      "My collection is missing 어문학 Vol.60 No.1. Total articles are 32\n",
      "My collection is missing 어문학 Vol.59 No.4. Total articles are 31\n",
      "My collection is missing 어문학 Vol.59 No.3. Total articles are 29\n",
      "My collection is missing 어문학 Vol.59 No.2. Total articles are 28\n",
      "My collection is missing 어문학 Vol.59 No.1. Total articles are 30\n",
      "My collection is missing 어문학 Vol.58 No.4. Total articles are 35\n",
      "My collection is missing 어문학 Vol.58 No.3. Total articles are 34\n",
      "My collection is missing 어문학 Vol.58 No.2. Total articles are 34\n",
      "My collection is missing 어문학 Vol.58 No.1. Total articles are 33\n"
     ]
    }
   ],
   "source": [
    "total_missing = 0\n",
    "missing_journals = []\n",
    "for journal_no, journal in enumerate(comparison):\n",
    "    vol = journal[1]\n",
    "    no = journal[2]\n",
    "    info = journal[0]+\" Vol.\"+str(vol)+\" No.\"+str(no)\n",
    "    my,gov = journal[-2:]\n",
    "    if gov:\n",
    "        if not my:\n",
    "            missing_journals.append([journal[0],vol,no,len(gov)])\n",
    "            print (\"My collection is missing {}. Total articles are {}\".format(info,len(gov)))\n",
    "            total_missing+=len(gov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1080,
   "id": "bb8ef5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total, missing 1769 articles\n"
     ]
    }
   ],
   "source": [
    "print (\"In total, missing {} articles\".format(total_missing))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1100,
   "id": "9f49ca7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_info = []\n",
    "for journal in missing_journals:\n",
    "    volume = journal[1:3]\n",
    "    vol,no = volume\n",
    "    article_count = journal[-1]\n",
    "    for issue in gov_website[journal[0]]:\n",
    "        info,articles = issue\n",
    "        if volume == info[:2]:\n",
    "            date,status,count,link = info[2:]\n",
    "            missing_info.append([journal[0],vol,no,date,status,article_count,link])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1101,
   "id": "1ca19c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['력사,법률',\n",
       " 62,\n",
       " 2,\n",
       " '2016-06-17',\n",
       " '입수',\n",
       " 27,\n",
       " 'https://unibook.unikorea.go.kr/material/articles;jsessionid=PNVkA0Nz8Q61WtK5Sx8WI7aT.web11?checkinNo=83555&materialScope=SER&nation=kn&format=image&method=&fields=ALL&keywords=%EA%B9%80%EC%9D%BC%EC%84%B1&conjunctions=AND&fields=ALL&keywords=%EA%B9%80%EC%9D%BC%EC%84%B1%EC%A2%85%ED%95%A9%EB%8C%80%ED%95%99+%ED%95%99%EB%B3%B4&pageSize=10&sortField=publishYear&sortDirection=DESCENDING&uid=CAT-00000000000064418']"
      ]
     },
     "execution_count": 1101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_info[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1105,
   "id": "9ae956e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.io.formats.excel.header_style = None\n",
    "df = pd.DataFrame(missing_info)\n",
    "writer = pd.ExcelWriter('missing_journals.xlsx', engine='xlsxwriter')\n",
    "df.to_excel(writer, 'Sheet1',index=False)\n",
    "workbook = writer.book\n",
    "worksheet = writer.sheets['Sheet1']\n",
    "\n",
    "header_format = workbook.add_format({\n",
    "        'bold': True,\n",
    "        'text_wrap': True,\n",
    "        'valign': 'top',\n",
    "        'fg_color': '#d5fdfa',\n",
    "        'border': 1})\n",
    "\n",
    "header_info = [\"Journal Subject\",\"Volume\",\"No\",\"Date of Seizure\",\"Status\",\"Article Count\",\"Link\"]\n",
    "for col_num, value in enumerate(df.columns.values):\n",
    "    worksheet.write(0, col_num, header_info[col_num], header_format)\n",
    "writer.save()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 953,
   "id": "807b880f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 954,
   "id": "cc53a6c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['고구려시기 무덤건설규정연구', '리광희']"
      ]
     },
     "execution_count": 954,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gov_elements[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa92529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 963,
   "id": "d21bb1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_missing = [g for g in gov_elements if g not in my_elements]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a3481a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 964,
   "id": "de9eadf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['사회주의보건제도의 우월성을 높이 발양시켜 나가기 위한 현명한 령도', '오진명'],\n",
       " ['제2차 세계대전의 전패국-도이췰한드와 일본의 과거청산에 대한 비교분석', '김병철'],\n",
       " ['17세기 후반기이후 화폐류통에 대한 실학자들의 견해와 그 진보성', '리선희'],\n",
       " ['우리 나라에서 자본주의화폐제도의 발생발전과 그것을 저해한 일본침략자들의 책동', '김옥'],\n",
       " ['현대자본주의경제의 악성위기-디플레', '리영남']]"
      ]
     },
     "execution_count": 964,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_missing[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 965,
   "id": "051221c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2915"
      ]
     },
     "execution_count": 965,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(my_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 966,
   "id": "a49a90ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 966,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3,4,5]\n",
    "x,y = a[-2:]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cf96a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a777e86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab40a242",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5173154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe49cb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8a8afe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d2b2db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3d6446",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "738bb724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5635"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_articles = 0\n",
    "for subject,gov_data in gov_website.items():\n",
    "    for volume in gov_data:\n",
    "        total_articles+= len(volume[1])\n",
    "total_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "64e8f44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshtein_distance(str1, str2, ):\n",
    "    counter = {\"+\": 0, \"-\": 0}\n",
    "    distance = 0\n",
    "    for edit_code, *_ in ndiff(str1, str2):\n",
    "        if edit_code == \" \":\n",
    "            distance += max(counter.values())\n",
    "            counter = {\"+\": 0, \"-\": 0}\n",
    "        else: \n",
    "            counter[edit_code] += 1\n",
    "    distance += max(counter.values())\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "ab6d9481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(required_edits)  # == 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "c4aa1107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(\"all_differences.csv\", \"w\") as f:\n",
    "    wr = csv.writer(f)\n",
    "    wr.writerows(all_differences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "f619d773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hell\u001b[38;5;16;48;5;1mo\u001b[0mo world\u001b[38;5;16;48;5;2m!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import difflib\n",
    "import wasabi\n",
    "from wasabi import color\n",
    "\n",
    "def diff_strings(a, b):\n",
    "    output = []\n",
    "    matcher = difflib.SequenceMatcher(None, a, b)\n",
    "    for opcode, a0, a1, b0, b1 in matcher.get_opcodes():\n",
    "        if opcode == \"equal\":\n",
    "            output.append(a[a0:a1])\n",
    "        elif opcode == \"insert\":\n",
    "            output.append(color(b[b0:b1], fg=16, bg=\"green\"))\n",
    "        elif opcode == \"delete\":\n",
    "            output.append(color(a[a0:a1], fg=16, bg=\"red\"))\n",
    "        elif opcode == \"replace\":\n",
    "            output.append(color(b[b0:b1], fg=16, bg=\"green\"))\n",
    "            output.append(color(a[a0:a1], fg=16, bg=\"red\"))\n",
    "    return \"\".join(output)\n",
    "    \n",
    "print(diff_strings(\"helloo world\", \"hello world!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "28d21ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insert\n",
      "equal\n",
      "delete\n",
      "equal\n",
      "delete\n"
     ]
    }
   ],
   "source": [
    "matcher = difflib.SequenceMatcher(None, a, b)\n",
    "for opcode, a0, a1, b0, b1 in matcher.get_opcodes():\n",
    "    print (opcode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793daf52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd090b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
