김일성종합대학학보 수 학 주체110(2021)년 제67권 제1호 정면 및 측면페장X-ray화상의 분류를 위한  한가지 심층학습방법 최일수, 조선향 경애하는 동지께서는 다음과 같이 말씀하시였다. 《과학자, 기술자들은 당이 마련해준 과학기술룡마의 날개를 활짝 펴고 과학적재능 과 열정을 총폭발시켜 누구나 다 높은 과학기술성과들을 내놓음으로써 부강조국건설에 이바 지하는 참된 애국자가 되여야 합니다.》 우리는 심층신경망을 리용하여 페장X-ray화상자료기지에서 정면화상과 측면화상을 분류하는 한가지 방법을 제기하고 실험을 통하여 효과성을 검증하였다. 선행연구[1]에서는 중첩층을 리용하여 심층신경망에 의한 화상분류방법을 제안하였 고 그 효과성을 검증하였다. 선행연구[2]에서는 블로크안에서 조밀한 련결을 가지는 DenseNet를 리용하여 페장X-ray화상으로부터 질병을 분류하는 방법을 제안하였다. 이러한 방법을 리용하여 그 학습에 필요한 자료기지를 준비하여야 한다. 페장X-ray화상자료기지 MIMIC-CXR 2.0은 정면X-ray화상(60%)과 측면X-ray화상(40%) 을 포함한다. 정면X-ray화상과 측면X-ray화상은 서로 다른 특성을 가지며 이로부터 정면 X-ray화상에 의한 질병분류를 하자면 자료기지에서 정면X-ray화상을 갈라내여야 한다. 선행연구[3]에서는 자기부호화기를 리용하여 정상인 X-ray화상과 그와 구별되는 화상 을 갈라내는 방법과 정상X-ray화상에 의한 질병분류방법을 제안하였다. 선행연구[1, 3]은 다 화상분류를 위한 방법이지만 정면X-ray화상들만을 구별해내는 방 법에는 적당하지 않으며 더우기 심층신경망이 크고 연산량이 필요없이 큰 부족점을 가지 고있다. 또한 선행연구들에서는 완전감독학습에 대한 론의는 있었으나 X-ray화상자료기 지인 MIMIC-CXR 2.0의 경우 정면 및 측면에 대한 정보가 없는것으로 하여 완전감독학습 이 현실적으로 거의 불가능하게 된다. 론문에서는 심층학습에 의하여 정면과 측면X-ray화상을 분류하기 위한 비교적 가벼 운 심층신경망구조를 제안하고 MIMIC-CXR 2.0자료기지를 리용하여 그 효과성을 취급하 였다. １．정면 및 측면화상분류를 위한 심층신경망구조 화상분류를 위한 효과적이고 전형적인 망구조는 중첩층을 여러 단계 포함하고있다. 론문에서는 문제의 특성을 고려하여 3×3모양의 려파기크기를 가지는 중첩층들을 리용하 였다. 입력화상의 크기를 64×64로 정하고 출력특징량의 깊이가 각각 16, 32, 64, 128인 4개 의 중첩층을 배치하였다. 마지막중첩층을 제외한 모든 중첩층의 뒤에 2×2최대선택층을 배치하였으며 제일 마지막에 4×4크기의 평균선택층을 놓았다. 모든 중첩층의 활성화함수 로는 정규화선형함수(relu)를 리용하였다. － 64 － 종합대학학보 수학 주체110(2021)년 제67권 제1호 신경망의 마지막부분에 크기가 64와 1인 전결합층을 리용하였으며 첫 전결합층의 활 성화함수는 정선형함수이고 마지막전결합층의 활성화함수는 시그모이드함수이다. 손실함수로는 문제의 특성상 2진분류를 위한 교차엔트로피함수를 리용하였다. 이 망의 전체 파라메터개수는 105 761개(대략 0.1M)로서 분류를 위한 대표적인 신경 망들인 AlexNet(61M), VGG16(138M), ResNet50(25.5M), ResNet101(44.4M)보다 훨씬 적다. 망 의 구조에 따르는 층들과 파라메터개수는 표와 같다. 표．망의 구조에 따르는 층들과 파라메터개수 층이름(형태) 출력크기 파라메터개수 conv2d_1 (Conv2D) max_pooling2d_1 (MaxPooling2D) conv2d_2 (Conv2D) max_pooling2d_2 (MaxPooling2D) conv2d_3 (Conv2D) max_pooling2d_3 (MaxPooling2D) conv2d_4 (Conv2D) average_pooling2d_1 (AveragePooling2D) flatten_1 (Flatten) dense_1 (Dense) dense_2 (Dense) (None, 62, 62, 16) (None, 31, 31, 16) (None, 29, 29, 32) (None, 14, 14, 32) (None, 12, 12, 64) (None, 6, 6, 64) (None, 4, 4, 128) (None, 1, 1, 128) (None, 128) (None, 64) (None, 1) 448 0 4 640 0 18 496 0 73 856 0 0 8 256 65 총파라메터개수: 105 761 학습파라메터개수: 105 761 ２．신경망의 학습 및 검증 신경망은 MIMIC-CXR 2.0자료기지를 통하여 학습 및 검증하였다. 이 자료기지는 227 835번의 검사를 통하여 얻어진 377 110장의 X-ray화상으로 이루어져있다. 이 자료기 지는 화상이 정면인가 측면인가에 대한 유용한 정보를 포함하고있지 않다. 이로부터 먼저 정면 및 측면화상을 각각 564장, 512장을 우연적으로 선택하여 그중 각각 451장, 409장은 학습화상으로, 113장, 61장은 검증화상으로 리용하였다. 학습은 RMSProp방법에 의한 묶음크기 32, 반복회수 1 000인 소규모묶음학습으로 진행하였다. 자료증식은 화상전처리단계에서 45°범위내의 우연회전, 우연적인 너비/높이 밀기, 잘 라내기, 확대, 좌우뒤집기를 리용하였다. 학습손실, 학습정확도, 검증손실, 검증정확도그라프는 그림과 같다. 그림에서 알수 있는것처럼 과학습은 일어나지 않았으며 걸음 993에서 검증정확도가 1.0이고 검증오차가 제일 최소로 되였다. 이 무게화일을 리용하여 우연적으로 선택한        38 552장의 화상에 대한 정면 및 측면분류를 진행하였다. 이때 정확도는 99.74%에 도달 하였다. 이 38 552장의 화상을 추가하여 추가학습을 진행해보았지만 정확도의 증가가 크 게 나타나지 않았다. 실험결과는 정면과 측면화상 1 076장(전체 화상의 0.28%)으로 학습시킨 신경망으로 전체 페장X-ray화상을 효과적으로 분류할수 있다는것을 보여준다. 정면 및 측면페장X-ray화상의 분류를 위한 한가지 심층학습방법 － 65 － ㄱ) 학습손실 ㄴ) 학습정확도 ㄷ) 검증손실 ㄹ) 검증정확도 그림. 신경망의 학습 및 검증결과 참 고 문 헌 [1] Alex Krizhevsky et al.; Proceedings of the 25th International Conference on Neural Information Processing Systems, 1, 1097, 2012. [2] P. Rajpurkar et al.; arXiv:1711.05225, 2017. [3] J. P. Cohen et al.; arXiv:1901.11210, 2019. 주체109(2020)년 9월 5일 원고접수 A Deep Learning Method for Classifying Front and  Side Chest X-ray Images Choe Il Su, Jo Son Hyang In this paper, we propose a kind of deep learning method and a structure for classifying front and side chest X-ray images, and verify the efficiency on MIMIC-CXR 2.0 database. Keyword: deep learning