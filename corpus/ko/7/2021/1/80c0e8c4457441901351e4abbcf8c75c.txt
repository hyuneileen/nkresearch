김일성종합대학학보 수 학 주체110(2021)년 제67권 제1호 구간분석을 통한 심층신경망의 안정성검증의 한가지 방법 리철진, 최창일 경애하는 동지께서는 다음과 같이 말씀하시였다. 《과학기술부문에서 첨단돌파전을 힘있게 벌려야 하겠습니다.》 선행연구[1]에서는 비선형활성함수를 가지는 신경망의 안정성을 정의하고 한계모형 검사도구를 리용하여 안정성을 검증하기 위한 일반적인 한가지 방법을 제기하였다. 선행 연구[2]에서는 화상분류를 진행하는 신경망에 대하여 주어진 화상과 주어진 잡음에 관한 안정성을 정의하고 술어론리를 리용하여 검증하는 방법을 제기하였다. 선행연구[3]에서는 일정한 조건을 만족시키고 ReLU활성함수를 리용하는 신경망에 대하여 선행연구[2]에서 정의된 안정성을 검증하는 방법과 도구를 제기하였다. 선행연구[4]에서는 주어진 입력모 임에 관한 심층신경망의 안정성문제를 출력모임과 불안정모임의 사귐을 구하는 문제에로 귀착시키는 방법을 제기하였다. 론문에서는 활성함수에 대한 제한조건이 선행연구[3]에서보다 약화된 심층신경망의 안정성을 선행연구[4]에서 제기한 방법을 갱신하여 검증하는 한가지 방법을 제기하였다. 심층신경망 N 을 다음과 같은 4원조 ① 층들의 모임 | nLLL : {: k ② 무게곁수행렬들의 모임 k k bWL ,( , ) 개의 마디를 가진다. Act , 로 표시한다. l 0 k ≤≤ } {: WW k }{ = [ k }{ w 1 , (cid:34) , T}{ k w ,] n k }{ k w i ∈ n −R k 1 1, i ≤≤ n 1, k ≤≤ l } k ③ 편향벡토르들의 모임 }{ k {: bb = }{ k b [ 1 , (cid:34) , T}{ k b ,] n k }{ k b i ∈ R 1, i ≤≤ n 1, k ≤≤ l } k Act ④ 활성함수모임 1,{: k 심층신경망 bWL ,( { −kx 에 대하여 이 층의 출력벡토르 l } 의 층 ≤≤φ N = Act }1 k ) , , 르 l 1( k ≤≤ 가 층 Lk }{ky 는 다음과 같이 표시된다. ) 1−kL 로부터 받아들이는 벡토 k }{ y =φ k k }{}{ ( xW k + }{ k b ) 특히 심층신경망 N 의 출력층 lL 의 출력벡토르 }{ly 은 다음과 같이 표시된다. l }{ y Φ= ( x }0{ ), Φ ( x }0{ :) = ˆ φ l (cid:68)(cid:34)(cid:68) (ˆ φ 1 x }0{ ), :ˆ = φφ k k k }{}{ ( xW k + }{ k b ) (1) 정의 １[4] 심층신경망 bWL ,( , 에 대하여 식 (1)에 의해 얻어지는 모임 N = , Act ) 과 주어진 입력벡토르들의 유한모임 X R⊆ 0n Y = { y l }{ n l ∈ R l }{ | y Φ= ( x }0{ }0{ ), x ∈ X } 를 X 의 출력모임이라고 부른다. 또한 Φ 를 N 의 출력함수라고 부른다. 심층신경망의 검증에서는 특정한 입력벡토르들의 모임 X R⊆ 0n 에 대하여 그것의 출력 모임의 원소들이 취해서는 안되는 모임 R⊆ 을 X 에 관한 불안정모임이라고 부른다. XS ln 구간분석을 통한 심층신경망의 안정성검증의 한가지 방법 － 85 － 실례로 softmax활성함수를 리용하여 0부터 9까지의 필기체수자화상을 분류하는 심층 신경망모형이 있다고 하자. 이 신경망에 대하여 수자 2를 나타내는 유한개의 화상들을 입력모임으로 할 때 출력벡토르에서 2에 대응하는 성분값이 0.5보다 작지 않으면 2로 정 확히 분류된다. 이로부터 이 입력모임의 불안정모임 XS 는 S X = { y = [ y , (cid:34) , 0 y 9 ] ∈ R 10 | y 2 < }5.0 로 볼 수 있다. 일반적으로 불안정모임은 심층신경망의 구조와 입력모임에 따라 결정된다. 정의 ２ 신경망 와 입력벡토르들의 유한모임 0n , X 의 불안 이면 신경망 N 은 입력 X 에 대하여 안 X R⊆ Act 정모임 XS 와 출력모임 Y 에 대하여 정하다고 말한다. bWL ,( N = , , ) Y ∩ ∅=XS 정의 ３ R 우에서의 닫긴구간전부의 모임을 IR 로 표시하자. 함수 [ φ 에 대하 R →:φ 를 φ의 구간확장이라고 부른 를 만족시키는 함수 IR →:][φ xx , R∈ IR ( φ ]([ R ]) ), = x x 여 다. 마찬가지로 함수 Φ : n R → R m N∈mn ,( ) 에 대하여 [ Φ ]([ x 1 , x 1 ] × (cid:34) × [ x , n x n ]) xΦ= )( , x = [ 1 (cid:34) x , , nx ] R∈ n 이 성립하는 함수 [ Φ :] n IR → IR m 을 Φ 의 구간확장이라고 부른다. X R⊆ 에 대하여 iX 를 X 의 원소들의 i 째 성분들의 모 n차원벡토르들의 유한모임 X [min( [ X 로 표시한다. 임이라고 할 때 닫긴구간 들의 직적을 (cid:34)= ,1 max( )], X n ] i , n i [ X ] = [ x 1 , x 1 ] × (cid:34) × [ x , n x n ] IR∈ 에 대하여 Xw ([ ]) = (max = (cid:34) ,1 , n i x i − x ) i 를 [ X 의 너비라고 ] i ), n 정의 ４ 함수 Φ : R n → R mnm ,( ∈ N ) 의 구간확장 [ Φ :] n IR → IR m 이 임의의 [ X ], 1 [ X ] 2 부른다. n IR∈ 에 대하여 를 만족시키면 X [ Φ⇒ 1 [Φ 는 포함단조라고 부른다. ⊆ X ] [ ] [ ] 2 ]([ X ]) [ Φ⊆ ]([ X 1 ]) 2 정의 4로부터 다음의 보조정리를 얻는다. 보조정리 １ 함수 mnm ,( 때 임의의 n차원벡토르들의 유한모임 X 에 대하여 다음의 성질이 만족된다. 의 구간확장 n IR → Φ :] IR → Φ N R R ∈ m ) [ : n 이 포함단조일 Φ∈Φ⇒∈∀ x )( X x [ ] [ ]([ X ]) (2) 증명 ] [Φ 는 함수 Φ 의 구간확장이므로 , [ Φ= x )( ]([ Φ 이 성립한다. 또한 [ x 1 , x 1 ] ×(cid:34) × [ x , x ] , 가 성립하며 따라서 식 (2)가 만족된다.(증명끝) ]([ x 1 x 1 Φ × × x [ [ n n , , ] [ [ ] x x X (cid:34) x =∀ ] n ∈ ]) 에 대하여 x [ 1 (cid:34) x × × 1 [Φ 는 포함단조인 구간확장이므로  이며 ]) [ Φ⊆ ]([ ]) X x x ] n n , ] x 1 X [ ⊂ (cid:34) n ] n , 보조정리 1로부터 다음의 보조정리를 얻는다. 보조정리 ２ 함수 mnm ,( 때 임의의 n차원벡토르들의 유한모임 X 에 대하여 다음의 성질이 만족된다.  ([ 의 구간확장 n IR → [ Φ⊂ Φ :] IR ]([ → Φ Φ N R R ∈ ]) ]) X X m ) [ : n 이 포함단조일 (3) － 86 － 종합대학학보 수학 주체110(2021)년 제67권 제1호 증명 보조정리 1로부터 [ X∈∀x ] XΦ∈Φ x [ )( ]([ ]) 가 성립하며 따라서 식 (3) 에 대하여 이 만족된다.(증명끝) 보조정리 2로부터 신경망 N = bWL ,( , , Act ) 의 불안정모임 XS 에 대하여 출력함수 Φ 의 구간확장 ∅= 이면 N 은 X 에서 안정하다는것을 알수 있다. 의 입력벡토르들의 유한모임 X 와 그것 XS [Φ 가 포함단조이고 X ∩]) [Φ ]([ ] 출력함수 Φ 의 포함단조인 구간확장 [Φ 를 구하기 위하여 신경망의 활성함수에 대 ] 한 한가지 가정을 제기한다. , 가정 신경망 bWL ,( N = , Act ) 의 활성함수 (cid:34)=φ ,1 kk ( , l ) 는 단조증가함수이다. 즉 x ∀ 1 , x 2 ∈ R , x 1 x ⇒≤ 2 φ k ( x 1 ) ≤ φ k ( x 2 ) 심층신경망에서 리용되는 ReLU함수, tanh함수, 로지스틱함수, sigmoid함수 등 대부분 의 활성함수들은 모두 가정을 만족시킨다. 가정을 만족시키는 활성함수를 리용하는 신경망에 대하여 출력함수의 포함단조인 구 정리 가정을 만족시키는 신경망 간확장을 구성하는 한가지 방법을 제기한다. bWL ,( 임 X 에 대하여 다음과 같이 구성되는 함수 조이다. N = ] , , Act 와 N 의 입력벡토르들의 유한모 [Φ 는 출력함수 Φ 의 구간확장이며 포함단 ) [ Φ ]([ X ]) = ]ˆ[ φ l (cid:68)(cid:34)(cid:68) ˆ[ 1 X ]([ φ ]) (4) 여기서 시하면 ˆ[ φ k ]([ X k }{ [:]) = Wφ ]( k k }{ [ X k }{ ] + }{ k b ) = Y [ k }{ ] = [ y k }{ 1 , k }{ y 1 ] × (cid:34) × [ y k }{ n k , y }{ k n k ] (5) y }{ k i : = φ k p }{ k ij + }{ k b i p }{ k ij : = }{ k i y : = φ k p }{ k ij + }{ k b i }{ k p ij : = n k 1 − ∑ j 1 = n k 1 − ∑ j 1 = ⎛ ⎜ ⎜ ⎝ ⎛ ⎜ ⎜ ⎝ ⎞ ⎟ , ⎟ ⎠ ⎞ ⎟ , ⎟ ⎠ }{}{ k xw ij }{}{ k xw ij k j k j , , j k }{}{ k xw ij }{}{ k xw ij k j , , ⎧ ⎪ ⎨ ⎪⎩ ⎧ ⎪ ⎨ ⎪⎩ }{ k w ij }{ k w ij }{ k w ij }{ k w ij ≥ 0 < 0 ≥ 0 < 0 i ( (cid:34)= ,1 , n k ) (6) 이며 k }{ k { }1 − [ ] = X Y [ [Φ 가 출력함수 Φ 의 구간확장이라는것을 밝히자. 증명 먼저 이다. X X ], = ] [ ] ] [ }1{ 임의의 입력벡토르 x = (cid:34) , x [ 1 , nx 0 ] R∈ n 0 에 대하여 [ x 1 , x 1 ] ×(cid:34) × [ x , n 0 x n 0 ] 을 ][ x 로 표 ˆ[ ]([ xφ 1 ]) = [ y }1{ 1 , }1{ y 1 ] × (cid:34) × [ y , }1{ n 1 y }1{ n 1 ] y }1{ i = y }1{ i = }1{ xw ij j + }1{ b i ⎛ ⎜ φ ⎜ ⎝ n 0 ∑ j 1 = ⎞ ⎟ ⎟ ⎠ 로서 ˆ[ φ 1 ]([ x 1 , x 1 ] ×(cid:34) × , [ x x n 0 n 0 은 )(ˆ 1 xφ 와 같다. 마찬가지로 ˆ[ )(ˆ x [ φ φ 1 1 [Φ 는 출력함수 Φ 의 구간확장이다. ]) ]ˆ[ φ l (cid:68)(cid:34)(cid:68) (cid:68)(cid:34)(cid:68) Φ ] ˆ φ l ]([ ]([ ]) ]) = = x x Φ= x )( 가 성립하며 따라서 다음으로 [Φ 가 포함단조이라는것을 밝히자. ] 구간분석을 통한 심층신경망의 안정성검증의 한가지 방법 － 87 － [ X ⊆ ] 1 [ X 2 ] 인 [ X ] = [ x , x m 1, m 1, m ] × (cid:34) × [ x nm , 0 x nm , 0 ], m = 2,1 가 있다고 하자. 그러면 , x ,2 j ≤ x ,1 j ≤ x ,1 j ≤ x , ,2 j j (cid:34)= ,1 , n 0 (7) 이 성립한다. [ X m ], =m 2,1 에 ]ˆ[ 1φ 을 적용한 경우를 보기로 하자. ˆ[ φ 1 ]([ X m ]) = [ y }1{ 1, m , y }1{ 1, m ] × (cid:34) × [ y }1{ , nm 1 , y }1{ , nm 1 ], m = 2,1 y }1{ , im = φ 1 ( ∑ p }1{ ijm , + }1{ b i ), p }1{ , ijm = }1{ im , y = φ 1 p }1{ ijm , + }1{ b i p }1{ , ijm = ⎞ ⎟ , ⎟ ⎠ n 0 j 1 = n 0 ∑ j 1 = ⎛ ⎜ ⎜ ⎝ }1{ xw ij }1{ xw ij , jm , jm }1{ xw ij }1{ xw ij , jm , jm , , , , ⎧ ⎪ ⎨ ⎪⎩ ⎧ ⎪ ⎨ ⎪⎩ }1{ w ij }1{ w ij }1{ w ij }1{ w ij ≥ 0 < 0 ≥ 0 < 0 i ( (cid:34)= ,1 , n 1 ) 식 (7)로부터 }1{ ,1 ij 알수 있다. 또한 가정에 의하여 활성함수 }1{ p ,1 ij }1{ ,2 ij }1{ ,2 ij i ( ≥ ≥ p p p , = ,1 (cid:34) , n 1 , j = ,1 (cid:34) , n 0 ) 이 성립한다는것을 쉽게 (cid:34)=φ ,1 , l ) 는 단조증가함수이므로 y }1{ ,1 i = }1{ p ,1 ij + }1{ b i p }1{ ,2 ij + }1{ b i y }1{ ,2 i }1{ y ,1 i = }1{ p ,1 ij + }1{ b i p }1{ ,2 ij + }1{ b i y }1{ ,2 i ≥ kk ( ⎞ ⎟ ⎟ ⎠ ⎞ ⎟ ⎟ ⎠ ], ≤ i φ 1 j 1 = n 0 ∑ ⎛ ⎜ ⎜ ⎝ ⎛ ⎜ ⎜ ⎝ (cid:34)= ,1 ∑ n 0 1 = j φ 1 = ⎞ ⎟ ⎟ ⎠ ⎞ ⎟ ⎟ ⎠ ˆ[ φ 1 = n 0 ∑ j 1 = n 0 ∑ j 1 = φ 1 ⎛ ⎜ ⎜ ⎝ ⎛ ⎜ ⎜ ⎝ }1{ y ] i ,1 φ 1 이 성립하며 따라서 [ y }1{ i ,1 , ⊆ [ y }1{ i ,2 , y }1{ i ,2 , n 1 로서 ]([ X ]) ⊆ 1 ˆ[ φ 1 ]([ X 2 ]) 도 성립 한다. 즉 ]ˆ[ 1φ 은 포함단조이다.  X (cid:68)(cid:34)(cid:68) ]([ ˆ[ φ 1 1 ]ˆ[ 마찬가지로 φ l 이 증명된다.(증명끝) ]) ⊆ ]ˆ[ φ l (cid:68)(cid:34)(cid:68) ˆ[ φ 1 ]([ X ]) 2 도 성립하며 [Φ 가 포함단조라는것 ] 정리 1과 보조정리 2로부터 다음과 같은 따름을 얻게 된다. 따름 가정을 만족시키는 신경망 L ,( 임 X , 그것의 불안정모임 XS , 식 (4)－(6)과 같이 구성된 출력함수 Φ 의 구간확장 에 대하여 와 N 의 입력벡토르들의 유한모 [Φ ] 이면 N 은 X 에 대하여 안정하다. X ∩]) bW , ∅= Act ]([ Φ N = ) [ , XS 우의 따름에 기초하여 가정을 만족시키는 신경망 와 N 의 입력벡 토르들의 유한모임 X 와 그것의 불안정모임 XS 가 주어졌을 때 안정성을 검증하는 알고 리듬을 제기한다. 알고리듬 입력: 가정을 만족시키는 신경망 와 입력모임 , X 의 불 X R⊆ bW , bW , Act Act L ,( L ,( N N = = 0n ) ) , , 안정모임 XS ln R⊆ , 턱값 0>ε {[ X M ← 출력: 모임 Unsafe  단계 １: ]} 단계 ２: M 이 빈모임이면 단계 7로 넘어간다. 아니면 단계 3에로 넘어간다. 단계 ３: M 에서 한 원소 단계 ４: ]([ [ X 를 선택한다. 동시에 M 에서 그 원소를 제거한다. 가 빈모임이면 단계 2로 넘어간다. 아니면 단계 5로 넘어간다. Unsafe X ∩]) {}← [Φ , ] XS － 88 － 종합대학학보 수학 주체110(2021)년 제67권 제1호 ε>]) 이면 단계 6에로 넘어간다. 아니면 Unsafe 에 [ X 를 추가하고 단 ] = [ x 1 , x 1 ] × (cid:34) × [ x , n 0 x n 0 ] 에서 x i − x i = Xw ([ ],2/]) [ x i + Xw ([ ,2/]) x i ] 로 분할하여 [ X ], 1 [ X ] 2 ]) ([Xw 인 한 닫긴구간을 +i 를 구성하고 모임 M 에 추가한 다 x , i x [ 단계 ７: Unsafe 를 출력한다. 모임 Unsafe 가 빈모임이면 신경망 N 은 X 에 대하여 안정하다. 단계 ５: ([Xw 계 2로 넘어간다. 단계 ６: ] X [ 음 단계 2로 넘어간다. 참 고 문 헌 [1] L. Pulina et al.; AI Communications, 25, 2, 117, 2012. [2] X. Huang et al.; CAV, LNCS, 10426, 3, 2017. [3] G. Katz et al.; CAV, LNCS, 10426, 97, 2017. [4] W. Xiang et al.; IEEE Transactions on Neural Network and Learning Systems, 22, 5777, 2018. Safety Verification of Deep Neural Network Using Interval Analysis 주체109(2020)년 9월 5일 원고접수 Ri Chol Jin, Choe Chang Il A method based on interval analysis for safety verification of deep neural network is presented in this paper. Keywords: deep neural network, safety verification, interval analysis