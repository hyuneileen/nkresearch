김일성종합대학학보 수 학 주체109(2020)년 제66권 제1호 잔차신경망을 리용한 객체화상분류기의 성능을 높이기 위한 한가지 구조변경방법 렴인혁, 최일수 위대한 수령 동지께서는 다음과 같이 교시하시였다. 《새로운 과학분야를 개척하며 최신과학기술의 성과를 인민경제에 널리 받아들이 기 위한 연구사업을 전망성있게 하여야 합니다.》(《전집》 제72권 292페지) 론문에서는 대표적인 중첩신경망인 ResNet-101에서 분류에 영향을 주는 제일 마지막 선택층을 변경시키는 한가지 방법을 제기하고 실험을 통하여 효과성을 검증하였다. 선행연구[1]에서는 신경망의 제일 마지막에 배치되여있는 선택층에서 평균선택을 진 행하였으며 실험결과들을 통하여 이 신경망이 객체식별에서 아주 효과적이고 선행연구 [2]에서 내놓은 신경망보다 성능이 더 좋다는것이 확증되였다. 그러나 선택층을 거치면서 식별에 영향을 주지 않는 특징을 영향을 보다 강하게 주는 특징과 같은 무게로 한것으로 하여 일부 경우들에 식별성능이 더 올라가지 못하였다. 선행연구[3]에서는 선행연구[1]에서 제기된 선택층의 구조를 변경시켜 CIFAR-10/ CIFAR100, SVHN과 ImageNet자료기지에서 검증하여 선행연구[1]에서보다 분류정확성을 개선하였다. 그러나 여기서도 선택층을 거칠 때 식별에 영향을 주지 않는 특징들을 같은 무게로 고려하였다. 론문에서는 선택층에 입력된 7×7pixel크기의 특징지도에서 분류에 영향을 크게 미치 는 부분과 적게 미치는 부분을 고려하여 선택층의 연산방법을 새롭게 설계하였으며 그 효과성을 Caltech-256자료기지를 통하여 검증하였다. 전형적인 중첩신경망의 구조는 몇개의 중첩층과 선택층으로 이루어진 층묶음을 여러 개 쌓고 전결합층을 쌓는 방법으로 구성된다. 객체식별을 위한 중첩신경망인 ResNet-101의 경우 입력층의 입력화상은 224× 224pixel, RGB화상이며 출력은 각 분류목표에 대한 확률값이다. ResNet-101의 훈련단계는 다음과 같다.[1] 단계 １ 련결무게들을 He초기화방법으로 초기화한다. 초기화는 평균과 표준편차가 아래와 같이 주어지는 정규분포에 따르는 우연량으로 진행한다. 한다. 0=μ , =σ /(2[ ni + n 0 )] ( in : 층의 입력련결개수, 0n : 층의 출력련결개수) 2/1 단계 ２ 준비된 훈련자료기지의 화상들을 다음의 흐름과정으로 통과시킨다. ① 화상의 전처리과정에서는 각이한 화상들을 망에 입력시키기 위한 전처리를 진행 전처리는 자르기와 보간을 리용하여 확대 및 축소하는 방법으로 진행한다. ② 망에서의 연산을 다음과 같은 흐름으로 진행한다. 중첩층(Convolution Layer)에서는 파라메터들에 의한 합성적연산을 진행한다. － 46 － 종합대학학보 수학 주체109(2020)년 제66권 제1호 선택층(Pooling Layer)에서는 최대선택(Max Pooling)을 로, 전역평균선택 u k = max j i , z ijk (Global Pooling)을 u = k z ijk 로 한다. 1 27 7 7 ∑∑ i 1 = j 1 = 정규화층(Batch Normalization)에서는 자료의 평균과 편차를 (0, 1)로 만든다. 예측층(Softmax Layer)에서는 ˆ p = k σ xs (( )) k = , K = 1 000 으로 놓는다. s k ( x )) exp( K exp( s ( x )) j ∑ j 1 = 단계 ３ 망출력결과 kpˆ 와 준비된 결과와의 차이를 통한 적응적모멘트최적화방법 (Adam Optimizer)으로 오차전파를 수행한다. 론문에서는 단계 2에서의 평균선택층의 연산을 변경시키는 방법으로 분류에 크게 영 향을 주는 부분과 적게 영향을 주는 부분을 고려하였다. 연산은 방정식 + 2 x 2 2 α 4/1 2 2 z 2 y 2 + 2 βα 2 4/1 2 α = 1 − 4/1 2 α x ≤≤ 4/1 2 , α − α y ≤≤ 0, z ≤≤ β , α ,1 ≥ β > 0 으로 표현되는 타원체면우에서 선택한 점들로 만든 행렬을 곱하여 진행한다. 려파기행렬 z 를 구하기 위하여 yx, 를 다음과 같이 정하고 웃식에 대입하면 x i = 3 , i − 3 y j = j 3 − 3 i ,( j = )7,1 , z =′ ij β (1 − y 2 j ) 2 x i + 2 2 α 이다. 려파기행렬을 얻은 다음 평균선택층연산을 다음과 같이 변경한다. 7 7 ∑∑ i 1 = j 1 = 7 u k = z ijk ′× z ij 7 2 7 ∑∑ i 1 = j 1 = z ′ ij , 2,1=k 048 그러면 화상이 매 층을 통과할 때 가장자리부분에 추가되는 의미없는 화소에 의한 영향을 보다 약화시키고 중심부분에 배치된 화소에 의한 영향을 보다 강화시키게 된다. 다음으로 분류목적을 변화시키기 위하여 전결합층의 세포수를 256개로 줄이고 변경 한 단계 2, 3의 과정을 반복하여 훈련을 진행한다. s ˆ p = k σ xs (( )) k = , K = 256 exp( K ( x )) k exp( s ( x )) j ∑ j 1 = 마지막으로 적합한 파라메터를 결정하기 위하여 추가한 연산층의 βα, 를 변화시키 면서 가장 성능이 높은것을 선택한다. 이렇게 훈련시킨 신경망의 정확성평가는 시험자료를 리용하여 얻는다. 제안한 방법의 효과성을 검증하기 위하여 Caltech-256자료기지를 리용하였다. 분류할 화상의 종류는 256가지로서 총 24 408장의 훈련화상과 6 103장의 검증화상을 리용하였다. 잔차신경망을 리용한 객체화상분류기의 성능을 높이기 위한 한가지 구조변경방법 － 47 － 훈련은 묶음의 크기는 20, 반복회수는 100으로 진행하였다.  파라메터수정은 α를 구간 [1.1, 6.1]에서 1간격으로, β를 구간 [1.1, 2.1]에서 0.1간격 으로 선택하면서 훈련 및 검증을 진행하였다. 검증은 우에서와 같이 βα, 를 변화시키면서 가장 좋은 분류성능이 나오는 상수를 찾고 이 상수에 의하여 제안된 ResNet-101과 기존의 ResNet-101의 오유률들을 비교하는 방법으로 진행하였다. 검증을 통하여 α 가 커질수록 려파기를 통과한 값이 특성지도의 평균값에 가까와간 다는것을 알수 있다. 또한 β 가 커질수록 특성지도의 중심에 위치하고있는 화소가 분류에 큰 영향을 주 도록 려파기가 구성된다는것을 알수 있다. 실험을 통하여 , 1.1=α 1.1=α , 2=β 인 경우에 가장 높은 성능을 낸다는것을 확인하였다. 2=β 일 때 변경한 망을 가지고 진행한 실험에서의 오유률은 표와 같다. 표．오유률 방법 기존의 ResNet-101 제안한 ResNet-101 훈련자료수/건 검증자료수/건 Top-1오유률/% Top-5오유률/% 24 408 24 408 6 103 6 103 19.28 17.86 4.61 3.97 실험결과는 론문에서 제안한 새로운 선택층을 가지는 신경망이 기존의 ResNet-101보 다 성능이 높다는것을 보여준다. 참 고 문 헌 [1] K. He; arXiv:1512.03385, 2015. [2] C. Szegedy; arXiv:1409.4843v1, 2014. [3] B. Zhang et al.; Neurocomputing, 321, 7, 36, 2018. 주체108(2019)년 9월 15일 원고접수 A Method of Structural Modification to Improve Accuracy of Image Classification Using Residual Network Ryom In Hyok, Choe Il Su We propose a method of structural modification to improve accuracy of image classification using Residual Network and verify it via tests. The experimental results show the efficiency of the method.  Keyword: ResNet