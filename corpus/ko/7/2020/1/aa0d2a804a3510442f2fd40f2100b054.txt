김일성종합대학학보 수 학 주체109(2020)년 제66권 제1호 혼합손실함수에 기초한 불균형학습자료를 가진  선형２진분류의 한가지 방법 백강훈, 김영민 경애하는 최고령도자 동지께서는 다음과 같이 말씀하시였다. 《첨단돌파전은 현대과학기술의 명맥을 확고히 틀어쥐고 과학기술의 모든 분야에서 세계를 앞서나가기 위한 사상전, 두뇌전입니다.》 론문에서는 현실에서 자주 제기되는 불균형학습자료를 가진 2진분류문제를 해결하기 위한 한가지 방법을 제기하였다. １. 불균형학습자료를 가진 2진분류에 관한 선행연구 얼굴검출과 같이 현실에서는 정의 실례들을 수집하기 힘들고 부의 실례들은 쉽게 수집할수 있는것으로 하여 불균형적인 학습자료가 주어질 때의 2진분류문제가 많이 제 기된다. 실례의 개수가 적은 클라스를 소수클라스, 실례의 개수가 상대적으로 많은 클라 스를 다수클라스라고 부른다. 지지벡토르기계나 신경망 등 많은 분류기들이 균형적인 학습자료를 전제로 하고있다. 만일 이러한 분류기들에 대하여 학습자료의 클라스간균형이 파괴되면 성능이 낮아진다. 학습자료의 불균형성을 해결하기 위한 연구들이 진행되였다. 가장 간단한 방법은 우연표본화를 진행하는것이다. 여기에는 소수클라스에 대한 올 리표본화방법과 다수클라스에 대한 내리표본화방법이 있다.[1] 이러한 방법을 일반적으로 클라스독립전처리방법이라고 부른다. 성능을 개선하기 위하여 우연적인 방법으로 표본화하는것이 아니라 불필요하거나 잡 음으로 간주되는 실례들만 삭제하는 지능적인 표본화방법들도 제기되였다. 그러나 올리표본화방법은 인위적인 부정확한 실례들이 추가될수 있고 내리표본화방 법은 불필요한 실례들에 대한 삭제를 신중하게 하여야 하며 이를 위해서는 효과적인 방 법과 일정한 처리시간이 요구된다. 선행연구[3]에서는 알고리듬수정법 즉 이미 있는 특정의 학습알고리듬을 수정하여 학습자료의 불균형성을 처리하기 위한 한가지 방법을 제기하였다. 이 방법은 클라스독립 전처리방법들에 비하여 좋은 성능을 나타내지만 처리시간이 오랜 결함을 가지고있다. 선행연구[2]에서는 분류기구성에서 많은 학습자료에 대하여 효률적인 처리를 진행하 기 위하여 통계적처리방법을 적용하였다. 론문에서는 불균형적인 학습자료가 주어질 때 실례개수가 크게 차이나는 매 클라스 에 적합한 손실함수에 기초하여 혼합손실함수를 정의하고 그에 기초하여 손실이 최소인 초평면을 결정하는 한가지 방법을 제기하려고 한다. 혼합손실함수에 기초한 불균형학습자료를 가진 선형2진분류의 한가지 방법 － 37 － ２. 혼합손실함수에 기초한 초평면결정방법 학습실례모임 D =− − { x i i y − 부의 실례모임 D −= }1 을 구성하자. = x {( , i y i ) i (cid:34)= ,1 , N } 으로부터 정의 실례모임 D =+ { x i y i += }1 과 + + |, | = D 를 결정하려고 한다. N 손실함수에 기초한 최량화문제를 설정하기 위하여 매 클라스에 대하여 각각 그에 적 라고 하자. 이때 분리초평면 )( x D | = N − = b f | T xw 합한 손실함수를 적용한다. 우선 소수클라스에 속하는 학습자료의 량은 적으므로 잘 알려진 접철손실함수 특히 다음과 같은 평활화된 접철손실함수인 Huber접철손실함수를 리용한다. ,0 ⎧ ⎪ 1( ⎨ ⎪ 1 ⎩ δ ≤<− 1 −≤ 1),2/( δ t ,2/ − t −− t )( lH δ δ = > 1 1 ) t t t 2 여기서 0≥δ 은 미리 정의된 상수이다. 이때 정의 실례들에 대한 손실을 다음과 같이 정의한다. (1) + L ( w , b ) = l H T xw ( i + b ) (2) + N ∑ i 1 = 한편 다수클라스에 속하는 학습자료의 량이 대단히 많은것으로 하여 잘 알려진 통계 적방법인 최소최대법[4]을 리용한다. 부의 실례들로부터 얻은 평균과 공분산행렬을 각각 그리고 Ω μ 를 평균이 μ이고 공분산행렬이 Σ 인 모든 분포들의 족이라고 하자. Σ ) ( , Σ,μ 라고 하자. Z 이로부터 전체 손실함수 즉 혼합손실함수를 다음과 같이 정의한다. Σ ) − L ( w , b ) = sup ( , μ Ω∈ T zw ( P Zz ~ ≥ b ) (3) − L + 선행연구[3]에 의하여 다음의 식이 성립한다. + L w w L = b b ) ( ) ( , , ( w , b ) (4) sup , ( Ω∈ μ Z Σ ) P ~ Zz T zw ( ≥ b ) = 1 2 1 + d (5) (b 2 d = 2 ) − T μw T ww Σ b,w 를 구하자. T zw ( sup ( , Ω∈ μ Z Σ ) P Zz ~ 이제 어떤 작은 정수 ε에 대하여 모든 분포우에서의 확률의 상한값이 ε보다 작아 지도록 하는 초평면의 파라메터 ≥ b ) ≤ ε (6) 우의 식으로부터 ε≤ 이다. 1 + 2 d 1 여기서 이다. － 38 － 종합대학학보 수학 주체109(2020)년 제66권 제1호 2d 을 웃식에 대입하고 계산하면 다음의 식을 얻을수 있다. T ww Σ bεε ( < T μw 1( − ) ) 2 − T ≥ μwb − 0 이다. μ 는 부의 실례들의 평균벡토르이므로 이로부터 다음의 식을 얻을수 있다. 이에 기초하여 일반지지벡토르기계에서와 류사하게 다음과 같은 목적식을 정의할수 T T bμwww +Σ ≤− 0 (7) + N ∑ i 1 = 1 ε − ε min , b w 1 2 2 || w || + C l H T xw ( i + b ) (8) 있다. 제한조건은 1 ε − ε T bμwww +Σ ≤− 0 T 이다. 여기서 C 는 최량여백과 손실최소화사이의 균형맞춤을 위한 조절상수이다. 최량화문제를 풀어 분리초평면의 파라메터들인 w 와 b 를 구하면 이 분리초평면은 정의 실례들과 부의 실례들에 대하여 손실이 동시에 최소로 되게 한다. ３. 실험 및 분석 론문에서 제기한 방법의 성능을 평가하기 위하여 동화상에서의 직립보행자검출실험 을 진행하였다. 준비한 동화상의 매 프레임으로부터 사람의 전신령역을 수동적으로 선택하여 정의 학습자료로 리용하고 나머지 임의의 령역에서 추출한것을 부의 학습자료로 리용하였다. 200 크기의 화상으로 표준화하고 주성분분석을 100 × 서로 다른 크기의 학습자료를 하여 32차원특징벡토르를 추출하였다. 학습을 위하여 정의 학습자료를 300개, 부의 학습자료를 25 000개 수집하였다. 이것 들중에서 각각 200개의 정의 학습자료와 20 000개의 부의 학습자료를 학습용으로 리용하 고 나머지를 검사용으로 리용하였다. 이 과정을 임의로 3번 진행하고 각각 성능을 평가 하였다. 실험결과는 다음표와 같다. 표. 실험결과 No. 성 능 1 92.3% 2 91% 3 93.1% 표에서와 같이 론문에서 제기한 방법은 불균형적인 학습자료를 가진 2진분류에서 비 교적 좋은 성능을 보여주었다. 이 방법은 많은 부의 학습자료들에 대하여 통계적인 방법으로 손실함수를 정의한것 으로 하여 일반지지벡토르기계와 같은 분류기보다 학습을 보다 효률적으로 진행할수 있다. 혼합손실함수에 기초한 불균형학습자료를 가진 선형2진분류의 한가지 방법 － 39 － 참 고 문 헌 [1] J. V. Hulse et al.; ICML, 935, 2007. [2] J. Honorio et al.; In Proceedings of the Seventeenth International Conference on Artiﬁcial Intelligence and Statistics, 384, 2014. [3] G. Lanckriet, et al.; J. Mach. Learn. Res. 3, 555, 2002. 주체108(2019)년 9월 15일 원고접수 A Method of Linear Binary Classification with Imbalanced  Training Examples Based on Mixed Loss Function Paek Kang Hun, Kim Yong Min In this paper we suggested a method of designing linear binary classifier that classified the imbalanced data using the mixed loss function. Keywords: mixed loss function, imbalanced training example, binary classification