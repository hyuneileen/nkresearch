김일성종합대학학보 수 학 주체107(2018)년 제64권 제2호 단일클라스지지벡토르기계를 리용한 외부실례검출 및 2진분류의 한가지 방법 김원, 김영민 경애하는 최고령도자 동지께서는 다음과 같이 말씀하시였다. 《첨단과학기술분야에서 세계적경쟁력을 가진 기술들을 개발하기 위한 투쟁을 힘있게 벌려야 합니다.》(《조선로동당 제7차대회에서 한 중앙위원회사업총화보고》 단행본 39페지) 론문에서는 단일클라스지지벡토르기계를 리용하여 외부실례검출 및 2진분류를 진행하 는 한가지 방법을 제기하였다. １．문 제 설 정 실례로 근적외선분광기에 의한 건강에 해로운 두가지 형태의 미생물의 스펙트르분석 자료가 주어졌을 때 주어진 검사스펙트르자료로부터 이 균이 두가지 형태의 균에 속하는 가, 속한다면 어느 균인가를 식별하는 문제를 생각할수 있다. 이것은 결국 외부실례검출과 2진분류를 동시에 진행하는 문제로 된다. 단일클라스지지벡토르기계는 하나의 클라스표식을 가진 자료모임에 대하여 그 모임안 의 원소들을 포함하는 하나의 최소닫긴구를 얻는다.[1, 2] 단일클라스지지벡토르기계는 외 부실례검출에 많이 리용되였다. 지지벡토르기계는 전형적인 두 클라스분류기(2진분류기)이며 이것을 다클라스분류문제 에로 확장할수 있다. 그러나 단일클라스지지벡토르기계는 이러한 분류문제와는 달리 한개 표 식을 가진 자료들만 주어지는 경우 그러한 자료들과 기타 자료들의 분류, 다시말하여 주어 진 훈련실례모임은 모두 정의실례이고 부의실례는 전혀 주어지지 않는 경우 분류를 진행 할수 있도록 해준다. 선행연구[3]에서는 단일클라스지지벡토르기계를 리용하여 2진분류를 진행하는 한가지 방 법을 제기하였다. 여기서는 초평면에 의한 단일클라스지지벡토르기계를 리용하였는데 두 클 라스들사이의 여백최대화는 론의하지 않았다. 론문에서는 선행연구[3]에서와는 달리 초구에 기초한 단일클라스지지벡토르기계를 리 용하여 외부실례검출 및 2진분류를 진행하는 한가지 방법을 제기하였다. ２．단일클라스지지벡토르기계를 리용한 외부실례검출 및 2진분류 외부실례훈련자료는 주어지지 않고 오직 2개의 클라스표식을 가진 훈련실례가 다음과 같이 주어졌다고 하자. D = {( x i , y i |) x i ∈ R l , y i ∈ ,1{ − },1 i (cid:34)= ,1 , N } － 28 － 종합대학학보 수학 주체107(2018)년 제64권 제2호 여기서 N 은 전체 훈련실례의 수이다. 이제 훈련실례중 p 개가 정의실례라고 하자. 일반 성을 잃지 않고 정의실례들은 1부터 p 까지의 번호를 가지고 나머지는 모두 부의실례라 고 하자. 특징공간에서 2개 초구의 사귐은 하나의 초평면을 이룬다.  목적은 매 클라스에 대하여 훈련실례들이 반경이 최소인 하나의 닫긴초구안에 놓이는 동시에 2개의 클라스표식을 가진 훈련실례들이 사귐초평면으로부터 떨어져있도록 하는것 이다. 이제 2개 초구의 중심벡토르와 반경을 각각 a 1 , a 2 , RR , 1 2 라고 하자. 그리고 입력공간 으로부터 하나의 비선형넘기기 Φ 를 리용하여 보다 높은 차원의 특징공간에로 넘기기를 진 행한다고 하자. 우선 이러한 특징공간안의 하나의 점으로부터 사귐초평면까지의 거리에 관한 식을 유 도하자. 사귐초평면우의 한 점을 0z 이라고 하면 다음의 식이 성립한다. 이때 특징공간안의 한 점으로부터 초평면까지의 거리는 다음과 같다. 이로부터 다음과 같은 제한조건을 줄수 있다. y i Φ ( x )( a i 2 − a 1 ) − ( 2 R 1 − R 2 2 − 2 a 1 + a 2 2 ) 1 2 ⎤ ερ−≥⎥ i ⎦ 여기서 iε 는 완화변수이다. 이때 초평면으로부터 떨어져있는 두 클라스사이의 여백은 ρ a − 2 || a 1 || 이다. ⎧ || ⎪ ⎨ ⎪⎩ || z 0 − a 1 z 0 − a 2 2 || = 2 || = 2 R 1 2 2 R ( az 0 2 − a 1 ) = ( 2 R 1 − R 2 2 − 2 a 1 + a 2 2 ) 1 2 Φ ( x )( a i 2 − a 1 ) − ( 2 R 1 − R 2 2 − 2 a 1 + a 2 2 ) 1 2 a 2 || − a 1 || d = ⎡ ⎢ ⎣ min , , , ρεηξ , J = ( min , , , ρεηξ , ar , ar , 2 R 1 + R 2 2 ) || Φ ( x ) − i a 1 2 || ≤ 2 R 1 + ξ i , (cid:34)∈∀ ,1{ i , p } || Φ ( x ) − a i 2 2 || ≤ R 2 2 + η i , (cid:34)+∈∀ p ,1 { i , N } y i Φ ( x )( a i 2 − a 1 ) − ( 2 R 1 − R 2 2 − 2 a 1 + a 2 2 ) , (cid:34)∈∀ ,1{ i , N } ⎡ ⎢ ⎣ 1 2 ⎤ −≥⎥ ⎦ ερ i 여기서 εηξ i i , , i ≥ 들은 완화변수들이다. ξ i ,0 η i ≥ ,0 ε i ≥ 0 부등식제한조건을 가진 최소화문제를 라그랑쥬형태에로 넘기면 다음과 같다. 단일클라스지지벡토르기계를 리용한 외부실례검출 및 2진분류의 한가지 방법 － 29 － N ∑ ( 1 Pi += 2 R 2 P ∑ i 1 = − N ∑ i 1 = ⎡ ⎢ ⎣ p ⎡ ⎢ ⎣ 2 RL = 1 + R 2 2 − ( 2 R 1 ξ Φ−+ i || ( x i ) − a 1 2 || ) α i − η Φ−+ i || ( x i ) − a 2 2 || ) β i − y i Φ ( ax )( − a 1 ) − 2 2 ( R 1 − R 2 2 2 − a 1 + a 2 2 ) 1 2 ⎤ +−⎥ ⎦ γερ i i + ⎤ ⎥ ⎦ N N P N N ∑ ξ i + + C C 1 η i 1 1 pi i = += 은 벌칙항이고 CCC 2 + ∑ 2 3 1 , , 3 − ξμ i i ∑∑ ε − i ηθ i i 1 1 pi i = += 는 라그랑쥬승수들이다. , , δθμγβα i i 1 i = , ∑ ∑ εδ i i − 1 = , , i i i i i 이제 매 변수들에 관하여 도함수를 취하고 령으로 놓으면 다음과 같다. C 여기서 2 −= Φ ( x i ) α i + 2 a 1 y i Φ ( x i ) γ i − a 1 y γ i i = 0 (1) L ∂ a ∂ 1 p ∑ i 1 = N L ∂ a ∂ 2 −= ∑ 2 Φ 1 pi += p N ∑∑ α + i i 1 = N i 1 = N ∑∑ β − i 1 pi += 1 = i N ∑ i 1 = N ∑ i 1 = ( x i ) β i + 2 a 2 y i Φ ( x i ) γ i + a 2 y γ i i = 0 (2) 이로부터 다음과 같은 식을 얻을수 있다. N p = 2 (3) = 2 (4) L ∂ R ∂ 1 L ∂ R ∂ 2 = 2 R 1 − 2 R 1 α i + R 1 y γ i i = 0 = 2 R 2 − 2 R 2 − R 2 y γ i i = 0 p ∑ i 1 = N ∑ β i 1 pi += N ∑ i 1 = N ∑ i 1 = L ∂ ξ ∂ i L ∂ ∂ η i L ∂ ε ∂ i −= α i + C 1 − μ i = 0 −= β i + C 2 − θ i = 0 γ +−= i C 3 − δ i = 0 2 − ∑∑ α i y γ i i 1 i = N 1 i = N + ∑∑ 2 β i 1 pi += 1 = i y γ i i aC − = 1μ i i i C β θ = 2 i i C γ = 3 δ i − − p ∑ i 1 = N N ∑ i 1 = N ∑ i 1 = 2 a 1 = 2 Φ ( x i ) α i − y i Φ ( x i ) γ i 2 a 2 = ∑ 2 Φ 1 pi += ( x i ) β i + y i Φ ( x i ) γ i 월프의 쌍대문제에로 넘기면 다음과 같다. － 30 － 종합대학학보 수학 주체107(2018)년 제64권 제2호 W ) ( γβα , , = K α i ii + β i ii − K αα i ij j − ββ j i ij − p ∑ i 1 = N ∑ K 1 pi += p p ∑ i 1 = ∑ j 1 = p N N N ∑ ∑ K 1 pj += 1 pi += − 1 2 N N ∑∑ i 1 = j 1 = Kyy j i γγ i ij j + ∑∑ i 1 = j y γα i 1 = j j K ij − p N ∑∑ i 1 = j 1 = y γβ j i j K ij = 0 여기서 제한조건은 다음과 같다. ≥ C 1 α i ≥ ,0 C 2 ≥ β i ≥ ,0 C 3 ≥ γ i ≥ 0 2 − ∑∑ α i y γ i i = 2 p i 1 = N N i 1 = N y γ i i = 2 + ∑∑ 2 β i 1 pi += ) x K = , i ij j 1 = 이다. 우의 식에서 Φ ( x ) Φ⋅ ( x i ) = j ( xK i 순차최소최량화방법을 리용하여 풀이를 구할수 있다. 일단 라그랑쥬승수들이 계산되면 초구의 반경과 중심을 계산할수 있다. 식 (1)과 (3)으로부터 다음과 같은 식을 얻을수 있다. a 1 = Φ ( x i ) α i − y i Φ ( x i ) γ i 식 (2)와 (4)로부터 다음과 같은 식을 얻을수 있다. a 2 = ( x i ) β i + y i Φ ( x i ) γ i 1 2 N ∑ i 1 = 1 2 N ∑ i 1 = 라그랑쥬승수들이 계산되면 초구의 반경은 다음의 식을 만족시킨다. 2 R 1 || Φ= ( x ) − i a 1 Φ= ( x i ) Φ⋅ ( x a 2) Φ− 1 ( x i i ) + 2 || 2 a 1 = xK ( , i x i ) − − 2 xK ( i , x ) α j j + xKy i ( j , x ) γ j j + xK ( , j x l ) αα l j − xKy l ( j , x l ) γα l j + xKyy l ( j j , x l ) γγ l j R 2 2 || Φ= ( x ) − a i 2 Φ= ( x ) Φ⋅ ( i x i 2) − a Φ ( x ) + i 2 = ( xK i , x i ) − 2 || , i x ) β j j − xKy ( j , i x ) γ j j + , j x l ) ββ l j + p p ∑∑ j 1 = l 1 = a 2 2 N N ∑ ∑ ( xK 1 pl += 1 pj += 1 4 N N ∑∑ j 1 = l 1 = 1 4 N N ∑∑ j 1 = l 1 = p ∑ j 1 = − p N ∑∑ j 1 = l 1 = − 2 N ∑ ( xK 1 pj += + N N ∑ ∑ 1 pj += l 1 = p ∑ i 1 = N ∑ Φ 1 pi += N ∑ j 1 = N ∑ j 1 = xKy l ( j , x l ) γβ l j + xKyy l ( j j , x l ) γγ j l 검사실례 x 에 대하여 판정은 다음과 같이 진행한다. R 1 R 2 || ≤ || ≤ xf )( ,1 ,1 − = || || 2 ⎧ ⎪ ⎨ ⎪ ⎩ ,0 x a )( −Φ 1 x a )( −Φ 기타 단일클라스지지벡토르기계를 리용한 외부실례검출 및 2진분류의 한가지 방법 － 31 － ３．실 험 실험에서는 근적외선분광기로 얻은 두가지 미생물에 대한 스펙트르자료 60개를 훈련 실례로 리용하고 정의실례와 부의실례, 외부실례를 포함하는 검사실례를 따로 만들어 성능 평가를 진행하였다. 훈련에 리용한 매 미생물에 대한 스펙트르자료는 각각 30개이다. 성능을 비교하기 위하여 독립적인 2개의 단일클라스지지벡토르기계를 리용한 선행연 구[4]를 선택하여 실험을 진행하였다.(표) 실패개수 % 표. 성능평가실험결과 선행연구[4] 론문에서 제기한 방법 13 88.2 6 94.6 표에서 보는바와 같이 이것은 단일클라스지지벡토르기계를 독립적으로 구성하여 리 용하는 방법보다 서로 의존하는 분류기를 구성하여 리용하는것이 더 우월하다는것을 알 수 있다. 참 고 문 헌 [1] B. Schölkopf et al.; Adv. Neural Inf. Process. Syst., 12, 526, 2000. [2] D. M. J. Tax et al.; Pattern Recognition Letters, 20, 11, 1191, 1999. [3] B. Hanczar et al.; LNCS, 8724, 547, 2014. [4] M. Tohme, et al.; Pattern Recognition Letters, 32, 13, 1652, 2011. 주체106(2017)년 12월 5일 원고접수 An Outlier Detection and Binary Classification Method using One Class Support Vector Machines Kim Won, Kim Yong Min In this paper, we propose a new method for outlier detection and binary classification using two one class support vector machines dependent on each other. The experiment results show the proposed method is better than other preceding methods.  Key words: one class support vector machine, binary classification, outlier detection