Journal of Kim Il Sung University (Natural Science) Vol. 3 No. 4 Juche103(2014) Property of Goodness-of-Fit Test of the Errors in  Nonlinear Autoregressive Time Series  Models with −α Mixing Errors Kim Kyong Hui, Kim Ok Gyong Abstract We derived the asymptotic normality of test statistics ˆ , n TT n in nonlinear autoregressive time series models with stationary −α mixing error terms; therefore we extended previous re- search results obtained in the model with i.i.d error terms to more general case. Key word nonlinear autoregressive model Introduction  The great leader Comrade Kim Il Sung said as follows. “We should actively develop the major areas of basic sciences such as mathematics, physics, chemistry and biology so as to raise the national standard of science and tech- nology and find more effective solutions to the scientific and technical problems that arise in the different branches of the national economy.”(“KIM IL SUNG WORKS” Vol. 35 P. 313) It is meaningful to consider the goodness-of-fit-test of the error distribution in time series models. In autoregressive time series models, the goodness-of-fit test based on the residual empiri- cal process has been extensively studied. In [3, 4] researchers suggested the Bickel-Rosenblatt test statistic firstly based on the in- tegrated squared error of the kernel type density estimator from the residuals. In [5] derived the asymptotic normality of the test statistic under the null-hypothesis in linear autoregressive models with i.i.d error terms. In [2] showed that the Bickel- Rosenblatt test statistic also converges asymptotically to a normal distribution under a fixed alternative. In [1] derived asymptotic normality of the Bickel- Rosenblatt test statistic in nonlinear autoregressive time series models with i.i.d. errors. We consider the asymptotic normality of the Bickel-Rosenblatt test statistic for goodness- −α mixing er- of-fit test of error density in nonlinear autoregressive time series models with The test statistic is based on the integrated squared error of the nonparametric error den- sity estimate and the error density under the null-hypothesis. rors. － 3 － Journal of Kim Il Sung University (Natural Science) No. 4 Juche103(2014) 1. Model and Statistics Let (cid:34)±± } =iX i , ,2 ,0 ,1 { ing the model be a strictly stationary process of real random variables obey- X i = ( Xr θ 1 (cid:34) , − , i X ) + ε i pi − (1) where Θ∈θθ,r Moreover, the errors sity f and X X , is a family of known measurable functions for R }{ iε are assumed to be −α mixing random variables with common den- (cid:34) } are independent of (cid:34)= ( 1 , θθ from ,2,1 . =i qθ ) , , ,1 (cid:34) − i pi − ,{ iε R p → . The problem of interest is to test the hypothesis  1 : fH where 0f is a prescribed density, based on the data { fH 0 : , = f 0 X f ≠ 0 (cid:34)− , 1 p (2) , (cid:34) X X X . } , , , 1 0 n The proposed test is based on the integrated square deviation of a kernel type density es- timator form the expectation of the kernel error density.  (cid:34) Especially, let ,ˆ( ˆ = θθ 1 be an estimator for θ, and define the residuals Next, let K be a kernel density function and h ≡ be a sequence of positive numbers nh tending to zero, and we will define a kernel type estimator of the error density f )(t to be − Xr ( ˆ θ i i 1 − , (cid:34) , X pi − ), i = ,2,1 (cid:34) .         (3) T q )ˆ, θ ˆ X ε = i where tK h )( = /1( htKh /( ) ) . We also consider the kernel error density based on the true errors , εε 1 2 , (cid:34)  , nε )(ˆ t f n n 1 = ∑ n i 1 = ( tK h n − ),ˆ ε i Rt ∈ f n )( t n 1 = ∑ n i 1 = ( tK h n − ε i ), Rt ∈ . We use the integrated squared deviation of nfˆ from to test (2), i.e., we reject the null-hypothesis )(ˆ[ f t n ˆ T n = ∫ = ∫ 0H for the large values of the statistic xhtfxK ( )(E f t n ()( )) − n tfKdx )( h = ∗ , − K h ∗ f 0 ( t 2 )] dt .           (4) Note that nTˆ is an analogue of the Bickel-Rosenblatt statistic proposed in the case of the observable iε ’s T n = ∫ [ f n (E)( t − f ( t 2 ))] 0 dt (5) 2. Main Assumptions We first introduce the following assumption on the autoregressive function θr and on the estimator θ for θˆ . Assumption 1 Let We assume that, for all U ⊂Θ⊂ qR Ry ∈∀ be an open neighborhood of θ. q , ) , jU (cid:34) ∈ ,1 θθ = 1 θ q = k ( , , , (cid:34) , q － 4 － Property of Goodness-of-Fit Test of the Errors in Nonlinear Autoregressive Time Series … ∂ r θθ ∂ j 1 yMy )( )( ≤ , yMy )( )( ≤ 2 2 ∂ r θθθ ∂∂ j k where i , ) 1 − X E pi − (cid:34) , For +∞< , and 4 XM ( 1 4 ( XM 2 ∂ θθ ∂ j Assumption 2 We assume that there exists j ≤≤1 and i ≤≤1 , set Y ij E = q n i 1 − , (cid:34) , X pi − ) +∞< for 1≥i . Xr ( i 1 − , (cid:34) , X pi − ) . 1<α such that ijY satisfying Assumption 3 The any estimator ,ˆ( ˆ = θθ 1 (cid:34) , T q )ˆ θ for θ based on X , 0 isfies the law of iterated logarithm, i.e., there exists a constant C 1 0( < C 1 ∞< ) sat- , , 1 X (cid:34) nX such that n =∑ Y ij 1 i = α nO ( p ), j = ,2,1 (cid:34) , q . lim n sup ∞→ n log(log n ) |ˆ θθ − ≤ | C 1 . where |ˆ θθ − | = ˆ( θθ − j j 2) .              (6) q ∑ 1 j = We shall derive the asymptotic distribution of nT under 0H . In order to calculate the probability of type II error when nTˆ is used to test hypothesis 1H of hypothesis (2) in the (2), we shall consider the asymptotic distribution of nTˆ under in sense of dxx 2 )() ( fd . 0 − > ( ) f f f , 0 = ∫ 0 We conclude this part with some basic assumptions on the error density function f , the kernel density function K and bandwidth nh . Assumption 4 f is two order continuously differentiable with bounded first and second derivatives, and 2f is integrable. 2 K K K K ′′ ) ′ ( , nnh ′′ ( , 2 ′ ,) ∞→ hn 2 → n (0 are integrable. Assumption 5 K is a continuous bounded symmetric kernel with compact support. Assumption 6 K ′′′ exists and is bounded. ∞→2 Assumption 7  and Assumption 5 implies that ∫  3. Results Let︐s consider the asymptotic distribution of Bickel- Rosenblatt test statistic nT . First, we formulate a property of weak stationary random variables −α mixing.  Lemma 1 Suppose that stationary sequence If random variable ξ is measurable for t { tX satisfies strong mixing condition. ) .  and ∫ ∞<dxxKx ∞<dxxK )(2 )( . } ∞−ℑ and random variables η is measurable for < η | | C < . , 2 ∞ +ℑ τt and there exists following properties | Then we obtain ⋅ CC≤ 214|EE ηξ ξη E| − ξ | C 1 α . － 5 － Journal of Kim Il Sung University (Natural Science) No. 4 Juche103(2014) Lemma 2 Under assumptions 1, 3, we have the following. n −∑ ˆ( εε i i 1 i = (log(log ΟΡ )) = n ) 2 Lemma 3 Under assumptions 4－6, we have 2 hΟdt = n ( ), E K hOdt = n ( ) , 2 ⎤ ⎥ ⎥ ⎦ 2 E K ∫ ⎡ ⎢ ⎢ ⎣ ⎛ ⎜ ⎜ ⎝ ε i ⎛ − t ⎜ ′ ⎜ h ⎝ n ⎞ ⎟ ⎟ ⎠ ⎞ ⎟ ⎟ ⎠ E K ∫ ⎡ ⎢ ⎢ ⎣ ⎛ ⎜ ⎜ ⎝ ε i ⎛ − t ⎜ ′′ ⎜ h ⎝ n ⎞ ⎟ ⎟ ⎠ ⎞ ⎟ ⎟ ⎠ ⎤ ⎥ ⎥ ⎦ ∫ ⎡ ⎢ ⎢ ⎣ ∫ ⎡ ⎢ ⎢ ⎣ ⎛ ⎜ ⎜ ⎝ ⎛ ⎜ ⎜ ⎝ 2 ε 1 ⎛ − t ⎜ ′ ⎜ h ⎝ n ⎞ ⎟ ⎟ ⎠ ⎞ ⎟ ⎟ ⎠ ⎤ ⎥ ⎥ ⎦ ε 1 ⎛ − t ⎜ ′′ ⎜ h ⎝ n 2 ⎞ ⎟ ⎟ ⎠ ⎞ ⎟ ⎟ ⎠ ⎤ ⎥ ⎥ ⎦ 2 hΟdt = n ( ), E K hΟdt = n ( ) . Lemma 4 Suppose assumptions 1－7 hold. Then, under the following further assumptions on the bandwidth nh : (2 )1 − α 2/3 n − h n log(log n ) ∞→ (7) we have )(ˆ[ t f n ⎞ ⎟ ⎟ ⎠ Theorem 1 If the assumptions 4－7 hold, Bickel-Rosenblatt test statistics (log(log n 42 hn n log(log n 23 2 − α h n = Οdt hn n ⎛ ⎜ ⎜ ⎝ ⎞ ⎟ ⎟ ⎠ ⎛ ⎜ ⎜ ⎝ O )) )] ( t ∫ = + − n 1 ) f p n 2 p 2 .    (8) has the following properties: ① Under the null hypothesis fH 0 : = f 0 , as ∞→n T n = ∫ [ f n )( t − K ∗ f 0 ( t )] h 2 dt Thn n n − ⎡ ⎢ ⎣ 1 nh n ∫ 2 )( dxxK ⎤ →⎥ ⎦ ∫ 2,0 N ⎛ ⎜ ⎜ ⎝ ∞→n ② Under the alternative fH 1 : f ( ∗ − ≠ f 0 f 0 )) , as 2 Tn [ n − ∫ ( K h f 2 0 )( dxx ( KK ∗ 2 )() dxx ∫ .     (9) ⎞ ⎟ ⎟ ⎠ dxx )( ] → N 4 ,0( [(Var f − εf )( 0 1 )]) .      (10) Proof Note that we will establish asymptotic normality under the null hypothesis f = 0f and under fixed alternatives f ≠ with different rates of convergence in both cases. 0f Let f denote the “true” density function of the random variables iε . Recalling the definition of the statistic nT and the density estimator nf we obtain the following decomposition: 2 f ] K − = ∗ f T n 0 h n [ ∫ 2 2 n = ∑ ∫ i < j + 2 n n ∑ i 1 = dx = [ f n ∫ − K h ∗ f 2 )(] dxx + ∫ [2 f n − fK ∗ h ]( x ) dxg dxx )( + h g 2 h ∫ dxx )( = [ xK ( h − ε i ) − e ( xKx [)] ( h − ε i h ) − e h ( x )] dx + [( K ∗ g )( ε i h h ) − [( KE ∗ g )( ε i h )]] + h [ ( xK h − ε i ) − e h ( x )] dx + g )( dxx 2 h 2 where the functions e , h g h are defined by e n h = K h A straightforward calculation shows ∑∫ [ ( xK h − ε i ) − e h ( x )] 2 dx = 2 OdxxK )( + 1 nh ∫ ⎛ ⎜ ⎝ 1 n ⎞ ⎟ ⎠ P . g h = K h ∗ ( f − 0f ) , respectively. 1 2 n ∑ ∫ n ∗ 1 i = and f 1 2 n i 1 = － 6 － Property of Goodness-of-Fit Test of the Errors in Nonlinear Autoregressive Time Series … Consequently we obtain the stochastic expansion 2 2 )( dxxK )( dxx 2 )] T n K = − − − ∗ ( f f 2 h 0 ∫ ∫ 1 nh ∑ i < j n H ( , εε j i n ) + + OY i Ρ 2 n n ∑ i 1 = ⎛ ⎜ ⎝ 1 n ⎞ ⎟ ⎠ [ xK ( h − ε i ) − e ( xKx )][ ( h − ε j h ) − e h ( x )] dx , = ( K ∗ g )( ε i h h [E) − K ∗ g ( ε i h )] . h Define the first term in this decomposition as U = n H ( , εε j i ) n and note that nU Y i 2 2 n ∑ i j < does not depend on the density 0f specified by the null hypothesis. Obviously, metric, H for each Nn ∈ . ∞< H )] = ( εεε 2 1 |) , 1 n , ( εε 2 1 2 n [Elim,0] n ∞→ nH is sym- where  , H ( εε j n i ) = ∫ [Elim n ∞→ In fact, ∫ h and random variable in the integrate symbol denotes η and consider ))( xKxe h ( εεε i j ( xK h [(E ε j ε i [E H |) − − − − = e ] ) ( ) ( h n , i ( x |)) ε i ] dx εσ { s , s ≤ t } as Lemma 1, we obtain that where ξ 1 = sgn( (E | η ℑ )E) η − 0 ∞− where | − = ℑ {E ξ 1 η 1 sgn( )E} ξ 1 0 ∞− As the proof of lemma 1, we have  E − + ηξηξ 1 BPAP ) − ABP ( E| | | = 11 E − ) ( ( ) 1 − 0 ℑ ∞− | ηξη 0 (E({E|E} |{E|E = η ℑ ∞− and it is measurable for 0 ∞−ℑ , we have that ≤ |EE E| ηξηξ ηξηξ 1 1 E|4|EE )}E) − η 11 − − . 1 1 1 and used | ≤η . 4| BAP ( ) − BAP ( ) − BAP ( ) − BPAP ) ( ( ) + BPAP ) ( ( ) + BPAP ) ( ( 4|) ≤ α therefore, we have Thus since |{E|E η 0 ℑ ∞− |E} 16 )( ταη − ≤ where i −=τ | j | . }{ tε is a strictly mixing sequence with coefficient )(τα such that left-hand side of above equation converges zero as ξ And Let’s see ,) ηε − = = xK ( h ∞→τ − xK ( ε h j . ) i we obtain ταη ≤ )(4|E| Therefore, we have that . lim n ∞→ [E H ( εεε j i |) , i ] n = 0 . . By applying the result of lemma 1 again, As the same way, we can proof the other moment limit results. Applying the central limit theorem for degenerate U-statistics, we obtain the main result of theorem 1.□ Theorem 2 Suppose that assumptions 1－7 are satisfied. And suppose that the bandwidth nh satisfies the following: 2 n (2 )1 − α − h n 1 4 − − hn n n ) 2 log(log → 0 (11) (log(log n )) → 0 (12) Then, the test statistics nTˆ has the following properties: ① Under the null hypothesis ∞→n , as = f fH 0 : 0 － 7 － ⎤ ⎥ ⎥ ⎦ ⎡ )(ˆ(2 ⎢ f t n ⎢ ⎣ ∫ ⎛ ⎜ ⎜ ⎝ 1 nh n ⎞ ⎟ ⎟ ⎠ 2 Journal of Kim Il Sung University (Natural Science) No. 4 Juche103(2014) ˆ Thn n n − 2 )( dxxK 1 nh n ∫ ⎤ →⎥ ⎦ 2,0 f 2 0 ∫ N ⎛ ⎜ ⎜ ⎝ ∞→n )( dxx ( KK ∗ 2 )() dxx . ∫ ⎞ ⎟ ⎟ ⎠ ② Under the alternative fH 1 : ≠ f 0 , as ˆ Thn n n − ∫ K h ∗ ( f − 2 f 0 )) dxx )( → N 4,0( var[( f − εf )( 0 1 ))] . ⎡ ⎢ ⎣ ⎡ ⎢ ⎢ ⎣ Proof By (9) it is sufficient to show that ) Using the definition of nTˆ and nT , we can obtain that T n − ˆ( Thn n n = o p )1( . ˆ| T n − T n | ≤ )(ˆ( t f n ∫ − f n ( t )) 2 dt + − f n ( t )) 2 dt T n .     (13) 2/1 ⎤ ⎥ ⎥ ⎦ Therefore, from lemma 3 and the fact = OT n Ρ it follows that ˆ| T n − T n | = o p ⎛ ⎜ ⎜ ⎝ 1 hn n ⎞ ⎟ ⎟ ⎠ + O p ⎛ ⎜ ⎜ ⎝ 1 hn n n )) (log(log 4 nh n + ) log(log n 22 2 α − h n n ⎞ ⎟ ⎟ ⎠ = o p ⎛ ⎜ ⎜ ⎝ 1 hn n ⎞ ⎟ ⎟ ⎠ where (11) and (12) are also used. Hence, we completed the proof of the first part of theo- rem 2. Based on (10), to prove ˆ( Tn n − T n ) = ο Ρ )1( . By (10), we can obtain that )1(Ρ Therefore, by (8), (13) and (14), it follows that n OT = (14) ˆ| T n − T n = | o Ρ ⎛ ⎜ ⎜ ⎝ 1 n nh n ⎞ ⎟ ⎟ ⎠ + O Ρ ⎛ ⎜ ⎜ ⎝ 1 n 2 n )) (log(log 4 nh n + ) log(log n 22 2 α − h n n = o Ρ ⎛ ⎜⎜ ⎝ 1 n ⎞ ⎟⎟ ⎠ ⎞ ⎟ ⎟ ⎠ where we also used (11), (12) and the fact ∞→nnh Hence, we completed the proof of theorem 2.□  References . [1] F. Cheng et al.; Statistics and Probability Letters, 78, 50, 2008. [2] D. Bachmann et al.; Statistics and Probability Letters, 74, 221, 2005. [3] M. V. Boldin et al.; Ann. Statist., 6, 629, 1978. [4] H. L. Koul; Lecture Notes in Statistics, Springer, 134～166, 2002. [5] S. Lee et al.; Statistics and Probability Letters, 56, 23, 2002. － 8 －